{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "In this notebook, I am going to explore the data to become more familiar with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import os\n",
    "from rt_interview_RV import RV_code_snippet\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "import gensim.models\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import utils\n",
    "from copy import deepcopy\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    with open(name + \".pkl\", \"wb\") as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + \".pkl\", \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filename: str):\n",
    "    assert isinstance(filename, str)\n",
    "    with open(filename) as json_data:\n",
    "        data = json.loads(json_data.read())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(filename: str):\n",
    "    assert isinstance(filename, str)\n",
    "    with open(filename, 'rb') as pickle_file:\n",
    "        data = pickle.load(pickle_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pickle(x, filename: str):\n",
    "    assert isinstance(filename, str)\n",
    "    with open(filename, 'wb') as pickle_file:\n",
    "        pickle.dump(x, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_json(\"rt_interview_RV/dataset.json\")\n",
    "ref_vocab = read_json(\"rt_interview_RV/ref_vocab.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available data: 19742\n",
      "Number of reference vocabs: 95\n",
      "One sample from dataset to just become familiar with data type:\n",
      "{'description': 'Bainite formation from intercritical austenite is of great practical importance for the production of TRIP-assisted steels. Silicon and aluminium play important roles during this transformation by delaying carbide precipitation, thus favouring the carbon enrichment of untransformed austenite, which makes its stabilisation down to room temperature possible. Previous studies have shown a strong dependence of bainite formation kinetics on both chemical composition and transformation temperature. In the present work, the effect of silicon and aluminium contents on bainite formation kinetics is investigated experimentally using dilatometry combined with microscopical observations. The experimental results are analysed by comparison with thermodynamic parameters, such as the activation energy G* for nucleation of bainite and the carbon content CT0 corresponding to the T0-curve. It is shown that the faster transformation kinetics induced by the substitution of silicon by aluminium can be ascribed (i) to a higher driving force for nucleation, (ii) to a higher carbon content CT0 at the T0-curve and (iii) to the precipitation of carbide in austenite in steels with a low Al content.Peer reviewe', 'abstract_word_count': 171, 'title': 'Relative Influence of Aluminium and Silicon on the Kinetics of Bainite Formation from Intercritical Austenite', 'id': '13295543', 'year': 2008, 'authors': ['Mertens, Anne', 'Jacques, Pascal J.', 'Sietsma, Jilt', 'Delannay, Francis']}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of available data: {len(dataset)}\")\n",
    "print(f\"Number of reference vocabs: {len(ref_vocab)}\")\n",
    "print(f\"One sample from dataset to just become familiar with data type:\\n{dataset[15000]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shortest and longest words length in ref_vocab: 2 and 17\n"
     ]
    }
   ],
   "source": [
    "ref_vocab_len = [len(vocab) for vocab in ref_vocab]\n",
    "print(f\"The shortest and longest words length in ref_vocab: {min(ref_vocab_len)} and {max(ref_vocab_len)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the embedding of the reference vocabs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_vocab_matrix = read_pickle(\"rt_interview_RV/ref_vocab_matrix.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dimension of ref_vocab_matrix: (95, 100)\n"
     ]
    }
   ],
   "source": [
    "print(f\"the dimension of ref_vocab_matrix: {ref_vocab_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, The Embedding dimension for reference words is 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus = [doc['description'] for doc in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The production process of almost all modern steels involves austenitization formation of the austenite phase upon continuous heating. Many of the microstructural features and properties that are obtained upon subsequent cooling are to a large extend determined by the evolution of the microstructure and chemical inhomogeneities during austenitization. In spite of its importance, austenitization so far has received much less attention than the transformations on cooling; however, the interest is continuously increasing, especially for the development of new types of steels (Dual-Phase steel, TRansformation-Induced Plasticity steel etc.). The aim of the thesis is to develop knowledge and to gain better understanding of the formation of the austenite microstructure in steel during heating, e.g. austenite nucleation kinetics, austenite growth modes and morphologies, redistribution of carbon between the phases during the transformatio'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:17<00:00, 11.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from mat2vec.processing import MaterialsTextProcessor\n",
    "text_processor = MaterialsTextProcessor()\n",
    "\n",
    "clean_corpus = [text_processor.process(abstract) for abstract in tqdm(text_corpus[:200])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_corpus = [' '.join(item[0]) for item in clean_corpus]\n",
    "corpus = ' \\n'.join([' '.join(item[0]) for item in clean_corpus])\n",
    "with open(\"mat2vec/training/data/my_file\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can build the corpus for training by running the followin line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.preprocess(\"rt_interview_RV/dataset.json\", \"corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus(object):\n",
    "    \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath('lee_background.cor')\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, word in enumerate(model.wv.vocab):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    model.save(temporary_filepath)\n",
    "    #\n",
    "    # The model is now safely stored in the filepath.\n",
    "    # You can copy it to other machines, share it with others, etc.\n",
    "    #\n",
    "    # To load a saved model:\n",
    "    #\n",
    "    new_model = gensim.models.Word2Vec.load(temporary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(temporary_filepath)\n",
    "more_sentences = [\n",
    "    ['Advanced', 'users', 'can', 'load', 'a', 'model',\n",
    "     'and', 'continue', 'training', 'it', 'with', 'more', 'sentences']\n",
    "]\n",
    "model.build_vocab(more_sentences, update=True)\n",
    "model.train(more_sentences, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# cleaning up temporary file\n",
    "import os\n",
    "os.remove(temporary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load('mat2vec/training/models/model_example')\n",
    "oldmodel = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10328.8701171875"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_args_(args, params):\n",
    "    \"\"\"updates args in-place\"\"\"\n",
    "    dargs = vars(args)\n",
    "    dargs.update(params)\n",
    "    \n",
    "params = {'window':5, 'negative':10}\n",
    "\n",
    "update_args_(model, params)\n",
    "#vars(model).update(params)\n",
    "vars(model)\n",
    "model.get_latest_training_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess(\"rt_interview_RV/dataset.json\")\n",
    "#new_data = read_pickle('corpus')\n",
    "#sentences = LineSentence('mat2vec/training/data/corpus')\n",
    "sentences = LineSentence('mat2vec/training/data/my_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cd mat2vec/training\n",
    "#!ls\n",
    "model.build_vocab(sentences, update=True)\n",
    "my_model = model.train(sentences, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "#oldmodel.save('newmodel')\n",
    "#model = Word2Vec.load('newmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580758, 1263360)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(oldmodel.wv.most_similar('martensitic'))\n",
    "except KeyError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 63.67it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mat2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1e15badd1170>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"rt_interview_RV/dataset.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Python_Scripts\\iris_ai\\utils.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(dataset_json, output_name)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclean_corpus\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mat2vec'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'training'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mwrite_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mat2vec' is not defined"
     ]
    }
   ],
   "source": [
    "utils.preprocess(\"rt_interview_RV/dataset.json\", \"my_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3085"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval('model').wv.vocab['the'].count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing RV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RV_code_snippet.calculate_rv_coefficient_of_arrays(ref_vocab_matrix, ref_vocab_matrix, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2910803.5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = gensim.models.Word2Vec.load('mat2vec/training/models/model_v3')\n",
    "new_model.get_latest_training_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03259757669491132"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RV_code_snippet.calculate_rv_coefficient(ref_vocab, ref_vocab_matrix, new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('metallurgical', 0.9985067248344421),\n",
       " ('slab', 0.9976663589477539),\n",
       " ('starting', 0.9975600242614746),\n",
       " ('additionally', 0.997474193572998),\n",
       " ('all', 0.997473418712616),\n",
       " ('whereas', 0.9974271059036255),\n",
       " ('transverse', 0.9972761273384094),\n",
       " ('finer', 0.9971984624862671),\n",
       " ('weight', 0.9971099495887756),\n",
       " ('element', 0.9971075057983398)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.wv.most_similar(\"magnetic\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
